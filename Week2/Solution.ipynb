{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_SGP_WEEK2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kid-116/ISTE-DL-SGP-21/blob/Week2/Week2/solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuZbgWonnGeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd1d728-5db7-46d0-d58f-7b77af836abe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/ISTE SGP DL 2021 WEEK-1 Assignment"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/ISTE SGP DL 2021 WEEK-1 Assignment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omrb1QOhnHr3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "from lr_utils import load_dataset     # for loading dataset\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CxjH4JQnNmM"
      },
      "source": [
        "# Loading the data (cat/non-cat)\n",
        "train_set_x, train_set_y, test_set_x, test_set_y, classes = load_dataset()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiMVrOQlnORV"
      },
      "source": [
        "#New libraries needed\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tcp4hancCl"
      },
      "source": [
        "#Normalization \n",
        "train_set_x=train_set_x/255\n",
        "test_set_x=test_set_x/255"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mESTZ6ZXU14o",
        "outputId": "8a6c8f0d-248b-47d8-f5a7-f8981330b17b"
      },
      "source": [
        "print(train_set_x.shape, train_set_y.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(209, 64, 64, 3) (1, 209)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUiYzfdypi1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb63b3c6-3afa-4513-aabe-ad8bcae69308"
      },
      "source": [
        "model=keras.Sequential([\n",
        "                        keras.layers.Flatten(), #Here we are feeding our input image into the neural network, one parameter only\n",
        "                        keras.layers.Dropout(0.1),\n",
        "                        keras.layers.Dense(192, activation=\"relu\"),\n",
        "                        keras.layers.Dropout(0.1),\n",
        "                        keras.layers.Dense(192, activation=\"relu\"),\n",
        "                        keras.layers.Dropout(0.1),\n",
        "                        keras.layers.Dense(192, activation=\"relu\"),\n",
        "                        keras.layers.Dropout(0.1),\n",
        "                        keras.layers.Dense(1, activation=\"sigmoid\") #Here you decide the number of output neurons you have, and the actovation function you'd be using for this last layer. \n",
        "                                                                    #The parameters to be entered are in the order mentioned above. It has two parameters\n",
        "])\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])         \n",
        "model.fit(train_set_x,train_set_y.T,epochs=250) #Why is the train_set_y passed as it's transpose for the function\n",
        "                                                #Feel free to run the model for as many epochs as you'd like and see if you get better results"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 22ms/step - loss: 0.1225 - accuracy: 0.9521\n",
            "Epoch 206/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1674 - accuracy: 0.9166\n",
            "Epoch 207/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1487 - accuracy: 0.9388\n",
            "Epoch 208/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1176 - accuracy: 0.9466\n",
            "Epoch 209/250\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.1239 - accuracy: 0.9401\n",
            "Epoch 210/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1779 - accuracy: 0.9105\n",
            "Epoch 211/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1574 - accuracy: 0.9433\n",
            "Epoch 212/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1261 - accuracy: 0.9489\n",
            "Epoch 213/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1309 - accuracy: 0.9428\n",
            "Epoch 214/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.7819 - accuracy: 0.7476\n",
            "Epoch 215/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.7994 - accuracy: 0.4532\n",
            "Epoch 216/250\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6778 - accuracy: 0.4746\n",
            "Epoch 217/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.5867 - accuracy: 0.6333\n",
            "Epoch 218/250\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.5941 - accuracy: 0.4719\n",
            "Epoch 219/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.5509 - accuracy: 0.6745\n",
            "Epoch 220/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.4991 - accuracy: 0.8274\n",
            "Epoch 221/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.4869 - accuracy: 0.8223\n",
            "Epoch 222/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.4188 - accuracy: 0.8445\n",
            "Epoch 223/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.4081 - accuracy: 0.8457\n",
            "Epoch 224/250\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.3902 - accuracy: 0.8471\n",
            "Epoch 225/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.4036 - accuracy: 0.8301\n",
            "Epoch 226/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.4499 - accuracy: 0.8000\n",
            "Epoch 227/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.5738 - accuracy: 0.7206\n",
            "Epoch 228/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6436 - accuracy: 0.6603\n",
            "Epoch 229/250\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6162 - accuracy: 0.6576\n",
            "Epoch 230/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.5595 - accuracy: 0.7019\n",
            "Epoch 231/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.4876 - accuracy: 0.7019\n",
            "Epoch 232/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2897 - accuracy: 0.8317\n",
            "Epoch 233/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2749 - accuracy: 0.8183\n",
            "Epoch 234/250\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.2190 - accuracy: 0.8314\n",
            "Epoch 235/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2613 - accuracy: 0.8146\n",
            "Epoch 236/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2050 - accuracy: 0.8469\n",
            "Epoch 237/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2348 - accuracy: 0.8227\n",
            "Epoch 238/250\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.1886 - accuracy: 0.8362\n",
            "Epoch 239/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2086 - accuracy: 0.8179\n",
            "Epoch 240/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2076 - accuracy: 0.8766\n",
            "Epoch 241/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1668 - accuracy: 0.9187\n",
            "Epoch 242/250\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.1885 - accuracy: 0.8884\n",
            "Epoch 243/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1740 - accuracy: 0.9114\n",
            "Epoch 244/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1812 - accuracy: 0.9017\n",
            "Epoch 245/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1933 - accuracy: 0.8884\n",
            "Epoch 246/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1608 - accuracy: 0.9249\n",
            "Epoch 247/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1761 - accuracy: 0.9131\n",
            "Epoch 248/250\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2136 - accuracy: 0.8565\n",
            "Epoch 249/250\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.1859 - accuracy: 0.8851\n",
            "Epoch 250/250\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1844 - accuracy: 0.8863\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9c6d357ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1508 - accuracy: 0.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.150831937789917, 0.800000011920929]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9HpxNSILqkF",
        "outputId": "58391e8f-c91f-47ea-8e45-5450b9a16d63"
      },
      "source": [
        "model.evaluate(test_set_x,test_set_y.T)            #Expected accuracy is around 80%"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1508 - accuracy: 0.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.150831937789917, 0.800000011920929]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "670oI_5U9Zj2"
      },
      "source": [
        "#Couple of things you could try after evaluating the model: Try overfitting the model, by training for more number of epochs\n",
        "                                                        #.  Implement a keras.dropout() and see if your models accuracy improves\n",
        "                                                        #.  You can even add more number of dense layers and see how your model reacts."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
