{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Deep Learning SGP WEEK 3 Convolutional Neural Networks","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tqdm\nfrom socket import socket","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:42:41.869458Z","iopub.execute_input":"2021-05-30T06:42:41.869764Z","iopub.status.idle":"2021-05-30T06:42:42.022614Z","shell.execute_reply.started":"2021-05-30T06:42:41.869692Z","shell.execute_reply":"2021-05-30T06:42:42.021795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Our dataset is visible on the top right of the screen. We have two categories for images (covid, healthy) for both 'train' and 'validation' folders","metadata":{}},{"cell_type":"code","source":"\nCATEGORIES = ['covid', 'healthy']\nDATADIR = '../input/covidistesgp/CovidDataset/train'\nfor category in CATEGORIES:\n    path = os.path.join(DATADIR,category)\n    for img in os.listdir(path):\n        img_arr = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   \n        plt.imshow(img_arr, cmap='gray')\n        plt.xlabel(category)\n        plt.show()\n        break","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:42:42.024197Z","iopub.execute_input":"2021-05-30T06:42:42.02455Z","iopub.status.idle":"2021-05-30T06:42:42.882451Z","shell.execute_reply.started":"2021-05-30T06:42:42.024511Z","shell.execute_reply":"2021-05-30T06:42:42.881614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we use a python library called openCV to read and perform some operations on the input data, such as GRAYSCALING and RESIZING","metadata":{}},{"cell_type":"code","source":"IMG_SIZE=50\ntrain_data=[]\ntest_data=[]\n\ndef create_data(data_dir):\n    for category in CATEGORIES:\n        path=os.path.join(data_dir, category)\n        class_num=CATEGORIES.index(category)\n        \n        for img in (os.listdir(path)):                                             ## We use os to iterate over all our files in the directory \n            try:\n                img_arr=cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   ## GRAYSCALING\n                img_arr=cv2.resize(img_arr, (IMG_SIZE,IMG_SIZE))                   ## RESIZING\n                if(data_dir=='../input/covidistesgp/CovidDataset/train'):\n                    train_data.append([img_arr,class_num])\n                else:\n                    test_data.append([img_arr,class_num])\n            except exception as e:\n                pass","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:42:42.884438Z","iopub.execute_input":"2021-05-30T06:42:42.884957Z","iopub.status.idle":"2021-05-30T06:42:42.89236Z","shell.execute_reply.started":"2021-05-30T06:42:42.884916Z","shell.execute_reply":"2021-05-30T06:42:42.891519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_data('../input/covidistesgp/CovidDataset/train')\ncreate_data('../input/covidistesgp/CovidDataset/validation')\n\nprint(len(train_data))\nprint(len(test_data))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:42:42.893866Z","iopub.execute_input":"2021-05-30T06:42:42.894236Z","iopub.status.idle":"2021-05-30T06:43:06.529211Z","shell.execute_reply.started":"2021-05-30T06:42:42.8942Z","shell.execute_reply":"2021-05-30T06:43:06.528316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sample in train_data[:10]:\n    print(sample[1])","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:43:06.530559Z","iopub.execute_input":"2021-05-30T06:43:06.531116Z","iopub.status.idle":"2021-05-30T06:43:06.538021Z","shell.execute_reply.started":"2021-05-30T06:43:06.531076Z","shell.execute_reply":"2021-05-30T06:43:06.537008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Its pretty important that we randomise our images rather than having all covid images together and all healthy images together","metadata":{}},{"cell_type":"code","source":"import random\n\nrandom.shuffle(train_data)              ## Shuffling the dataset\n\nfor sample in train_data[:10]:\n    print(sample[1])","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:43:06.539367Z","iopub.execute_input":"2021-05-30T06:43:06.539749Z","iopub.status.idle":"2021-05-30T06:43:06.551081Z","shell.execute_reply.started":"2021-05-30T06:43:06.539714Z","shell.execute_reply":"2021-05-30T06:43:06.550244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train=[]\ny_train=[]\nx_test=[]\ny_test=[]\n\nfor features,label in train_data:\n    x_train.append(features)\n    y_train.append(label)\n    \nfor features,label in test_data:\n    x_test.append(features)\n    y_test.append(label)\n\nx_train = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)   ## reshaping the dataset to (length, 50, 50, 1)\nx_test = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\nprint(len(x_train))\nprint(len(x_test))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:43:06.552363Z","iopub.execute_input":"2021-05-30T06:43:06.552706Z","iopub.status.idle":"2021-05-30T06:43:06.567117Z","shell.execute_reply.started":"2021-05-30T06:43:06.55267Z","shell.execute_reply":"2021-05-30T06:43:06.566231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### After we've done this preprocessing work, its handy to store our final array instead of repeating this everytime we want to use these values\n### For this, we use the python library called pickle to store all the values and load them in directly later","metadata":{}},{"cell_type":"code","source":"import pickle\n\npickle_out_x_train = open(\"x_train.pickle\",\"wb\")          # open/create a file called x_train.pickle, and write into it         \npickle.dump(x_train, pickle_out_x_train)                  # dump the contents of the np array\npickle_out_x_train.close()                                # close the file\n\npickle_out_y_train = open(\"y_train.pickle\",\"wb\")\npickle.dump(y_train, pickle_out_y_train)\npickle_out_y_train.close()\n\npickle_out_x_test = open(\"x_test.pickle\",\"wb\")\npickle.dump(x_test, pickle_out_x_test)\npickle_out_x_test.close()\n\npickle_out_y_test = open(\"y_test.pickle\",\"wb\")\npickle.dump(y_test, pickle_out_y_test)\npickle_out_y_test.close()\n\nprint(len(x_train))\nprint(len(x_test))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:43:06.570401Z","iopub.execute_input":"2021-05-30T06:43:06.570741Z","iopub.status.idle":"2021-05-30T06:43:06.586734Z","shell.execute_reply.started":"2021-05-30T06:43:06.570708Z","shell.execute_reply":"2021-05-30T06:43:06.585728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pickle_in_x_train = open(\"x_train.pickle\",\"rb\")           # open the file\ntrainX = pickle.load(pickle_in_x_train)                   # load its contents into a python varriable\npickle_in_x_train.close()                                 # close the file\n\npickle_in_y_train = open(\"y_train.pickle\",\"rb\")\ntrainY = pickle.load(pickle_in_y_train)\npickle_in_y_train.close()\n\npickle_in_x_test = open(\"x_test.pickle\",\"rb\")\ntestX = pickle.load(pickle_in_x_test)\npickle_in_x_test.close()\n\npickle_in_y_test = open(\"y_test.pickle\",\"rb\")\ntestY = pickle.load(pickle_in_y_test)\npickle_in_y_test.close()\n\nprint(str(len(trainX)) + ', ' + str(len(testX)))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:43:06.5884Z","iopub.execute_input":"2021-05-30T06:43:06.588726Z","iopub.status.idle":"2021-05-30T06:43:06.602128Z","shell.execute_reply.started":"2021-05-30T06:43:06.588692Z","shell.execute_reply":"2021-05-30T06:43:06.600996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Expected: 2000, 200\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n\nprint(len(x_test))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:43:06.603269Z","iopub.execute_input":"2021-05-30T06:43:06.603629Z","iopub.status.idle":"2021-05-30T06:43:11.6161Z","shell.execute_reply.started":"2021-05-30T06:43:06.603594Z","shell.execute_reply":"2021-05-30T06:43:11.615193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now fill out the code in the below 2 cells following the instructions","metadata":{}},{"cell_type":"code","source":"### NORMALIZE the data (trainX, trainY) from 0-255 to 0-1, and convert trainX,trainY,testX,testY to np arrays\n### approx. (1 x 4) lines of code\ntrainX = np.array(trainX)\ntrainY = np.array(trainY).reshape(-1, 1)\ntextX = np.array(testX)\ntestY = np.array(testY).reshape(-1, 1)\ntrainX = trainX / 255\ntestX = testX / 255\nprint(trainX.shape)\nprint(trainY.shape)\nprint(testX.shape)\nprint(testY.shape)\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-30T06:43:11.617475Z","iopub.execute_input":"2021-05-30T06:43:11.617995Z","iopub.status.idle":"2021-05-30T06:43:11.645785Z","shell.execute_reply.started":"2021-05-30T06:43:11.617954Z","shell.execute_reply":"2021-05-30T06:43:11.645006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\n### Use model.add to add layers (example: conv2D layers, then Maxpooling2D layers, Dense)\n### Experiment with tf keras documentation to complete the model\n### approx 5-12 lines of code, feel free to experiment with different model structures\n\nmodel.add(Conv2D(filters=16, kernel_size=(6, 6), padding='same', activation='tanh', input_shape=(50, 50, 1)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(filters=18, kernel_size=(5, 5), padding='same', activation='tanh'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(filters=22, kernel_size=(4, 4), padding='same', activation='tanh'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(filters=24, kernel_size=(4, 4), padding='same', activation='tanh'))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='tanh'))\nmodel.add(Dense(100, activation='tanh'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam', metrics=tf.keras.metrics.AUC())\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:01:31.434895Z","iopub.execute_input":"2021-05-30T07:01:31.43524Z","iopub.status.idle":"2021-05-30T07:01:31.527241Z","shell.execute_reply.started":"2021-05-30T07:01:31.43521Z","shell.execute_reply":"2021-05-30T07:01:31.526442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(trainX, trainY, batch_size=32, epochs=5, validation_split=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:01:35.864139Z","iopub.execute_input":"2021-05-30T07:01:35.86446Z","iopub.status.idle":"2021-05-30T07:01:38.290257Z","shell.execute_reply.started":"2021-05-30T07:01:35.864432Z","shell.execute_reply":"2021-05-30T07:01:38.289466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(trainX, trainY, verbose = 1) \n\nprint('Train loss:', score[0]) \nprint('Train accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:01:40.37374Z","iopub.execute_input":"2021-05-30T07:01:40.37409Z","iopub.status.idle":"2021-05-30T07:01:40.611576Z","shell.execute_reply.started":"2021-05-30T07:01:40.374058Z","shell.execute_reply":"2021-05-30T07:01:40.610474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Expected training accuracy 90-98% ","metadata":{}},{"cell_type":"code","source":"score = model.evaluate(testX, testY, verbose = 0) \n\nprint('Test loss:', score[0]) \nprint('Test accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2021-05-30T07:01:42.836475Z","iopub.execute_input":"2021-05-30T07:01:42.836805Z","iopub.status.idle":"2021-05-30T07:01:42.901412Z","shell.execute_reply.started":"2021-05-30T07:01:42.836773Z","shell.execute_reply":"2021-05-30T07:01:42.900591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Expected Test Accuracy 70-80%","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}